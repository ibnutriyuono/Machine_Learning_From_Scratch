{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, X, y, kernel_type=\"linear\", max_iter=10000, C=1.0, tolerance=0.001):\n",
    "        # parameters\n",
    "        self.kernels = {\n",
    "            'linear': self.kernel_linear,\n",
    "            'quadratic': self.kernel_quadratic\n",
    "        }\n",
    "        self.kernel_type = kernel_type\n",
    "\n",
    "        self.max_passes = max_iter # max passes\n",
    "        self.C = C # regularization paramtere\n",
    "        self.tol = tolerance # tolerance\n",
    "\n",
    "        # input/training-data\n",
    "        self.X = X\n",
    "        self.N, self.D = self.X.shape\n",
    "        self.y = y\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        alpha = np.zeros((self.N, ))\n",
    "        b = 0\n",
    "        passes = 0\n",
    "        kernel = self.kernels[self.kernel_type]\n",
    "        while passes < self.max_passes:\n",
    "            num_changed_alphas = 0\n",
    "            for i in range(self.N):\n",
    "                Ei = self.get_Ek(i, self.get_w(alpha), b)\n",
    "                if(((self.y[i]*Ei) < -self.tol and alpha[i] < self.C) or ((self.y[i]*Ei) > self.tol and alpha[i] > 0)):\n",
    "                    j = self.get_rnd_int(self.N-1, i)  # Get random int i~=j\n",
    "                    Ej = self.get_Ek(j, self.get_w(alpha), b)\n",
    "\n",
    "                    alpha_old = np.copy(alpha) # save old alphas\n",
    "\n",
    "                    L,H = self.get_L_H(alpha[j], alpha[i], self.y[j], self.y[i])\n",
    "\n",
    "                    if(L == H):\n",
    "                        continue\n",
    "                    eta = -kernel(self.X[i], self.X[i]) -kernel(self.X[j], self.X[j]) + 2 * kernel(self.X[i], self.X[j])\n",
    "                    if(eta>=0):\n",
    "                        continue\n",
    "                    alpha[j] = alpha[j] - self.y[j]*((Ei - Ej)/eta)\n",
    "                    alpha[j] = max(alpha[j], L)\n",
    "                    alpha[j] = min(alpha[j], H)\n",
    "                    if(abs(alpha[j] - alpha_old[j]) < 1e-5):\n",
    "                        continue\n",
    "\n",
    "                    alpha[i] = alpha_old[i] + self.y[i]*self.y[j] * (alpha_old[j] - alpha[j])\n",
    "\n",
    "                    b1 = b - Ei - self.y[i]*(alpha[i] - alpha_old[i])*np.dot(self.X[i], self.X[i].T) - self.y[j]*(alpha[j] - alpha_old[j])*np.dot(self.X[i], self.X[j].T)\n",
    "                    b2 = b - Ej - self.y[i]*(alpha[i] - alpha_old[i])*np.dot(self.X[i], self.X[j].T) - self.y[j]*(alpha[j] - alpha_old[j])*np.dot(self.X[j], self.X[j].T)\n",
    "                    if((0 < alpha[i] and alpha[i] < self.C) and (0 < alpha[j] and alpha[j] < self.C)):\n",
    "                        b = (b1 + b2)/2\n",
    "                    elif((0 < alpha[i] and alpha[i] < self.C)):\n",
    "                        b = b1\n",
    "                    elif ((0 < alpha[j] and alpha[j] < self.C)):\n",
    "                        b = b2\n",
    "\n",
    "                    num_changed_alphas+=1\n",
    "\n",
    "            if(num_changed_alphas == 0):\n",
    "                passes+=1\n",
    "            else:\n",
    "                passes = 0\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.w = self.get_w(alpha)\n",
    "        self.b = b\n",
    "\n",
    "        # print(passes)\n",
    "\n",
    "        alpha_idx = np.where(alpha > 0)[0]\n",
    "        support_vectors = self.X[alpha_idx, :]\n",
    "        return support_vectors, passes\n",
    "\n",
    "    def predict(self, X):\n",
    "        # kernel = self.kernels[self.kernel_type]\n",
    "        # eval = np.sign(np.dot(np.multiply(self.alpha, self.y), kernel(X, X)) + self.b).astype(int)\n",
    "\n",
    "        return np.sign(np.dot(self.w, X.T) + self.b).astype(int)\n",
    "\n",
    "    def get_w(self, alpha):\n",
    "        return np.dot(np.multiply(alpha, self.y), self.X)\n",
    "\n",
    "    def get_rnd_int(self, n, z):\n",
    "        # TODO: If does not work, use external method\n",
    "        arr = np.arange(n)\n",
    "        np.random.shuffle(arr)\n",
    "        if arr[0] == z:\n",
    "            return arr[1]\n",
    "        else:\n",
    "            return arr[0]\n",
    "\n",
    "    def f(self, i, w, b):\n",
    "        return np.sign(np.dot(w.T, self.X[i].T) + b).astype(int)\n",
    "\n",
    "    def get_Ek(self, i, w, b):\n",
    "        # print(np.dot(w.T, self.X[i].T) + b, self.y[i], self.X[i])\n",
    "        return self.f(i,  w, b) - self.y[i]\n",
    "\n",
    "    def get_L_H(self, alpha_j, alpha_i, y_j, y_i):\n",
    "        if (y_i != y_j):\n",
    "            return (max(0, alpha_j - alpha_i), min(self.C, self.C - alpha_i + alpha_j))\n",
    "        else:\n",
    "            return (max(0, alpha_i + alpha_j - self.C), min(self.C, alpha_i + alpha_j))\n",
    "#\n",
    "    #  Define kernels\n",
    "    def kernel_linear(self, x1, x2):\n",
    "        return np.dot(x1, x2.T)\n",
    "    def kernel_quadratic(self, x1, x2):\n",
    "        return (np.dot(x1, x2.T) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_chosen = 1 # only this class is chosen\n",
    "y = np.asarray([-1 if y[i]!=class_chosen else 1 for i in range(y.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "C=1.0\n",
    "epsilon=0.001\n",
    "model = SVM(X_train, y_train, C=C, tolerance=epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vectors, iterations = model.fit()\n",
    "sv_count = support_vectors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(y, y_hat):\n",
    "    idx = np.where(y_hat == 1)\n",
    "    TP = np.sum(y_hat[idx] == y[idx])\n",
    "    idx = np.where(y_hat == -1)\n",
    "    TN = np.sum(y_hat[idx] == y[idx])\n",
    "    return float(TP + TN)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = calc_acc(y_test, y_hat)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support vector count: 103\n",
      "bias:\t\t15.526\n",
      "w:\t\t[-0.24997364 -5.45079904  0.76423562 -2.15426581]\n",
      "accuracy:\t0.733\n",
      "Converged after 10000 iterations\n"
     ]
    }
   ],
   "source": [
    "print(\"Support vector count: %d\" % (sv_count))\n",
    "print(\"bias:\\t\\t%.3f\" % (model.b))\n",
    "print(\"w:\\t\\t\" + str(model.w))\n",
    "print(\"accuracy:\\t%.3f\" % (acc))\n",
    "print(\"Converged after %d iterations\" % (iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
